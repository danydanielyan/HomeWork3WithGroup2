---
title: "Homework#3"
author: "Group 2"
date: '2022-08-10'
output: pdf_document
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
```

Part 1
1. Using read.csv() function import SW_EpisodeIV.txt file into R. You must get something like this:
## Rows: 1,011
## Columns: 2
## $ character <chr> "THREEPIO", "THREEPIO", "THREEPIO", "THREEPIO", "THREEPIO...
## $ dialogue <chr> "Did you hear that? They've shut down the main reactor. ...

```{r p1.1, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
dataframe = read.csv("SW_EpisodeIV.txt",sep= " ")
str(dataframe)

```
2. Using dialogue column create new column named  where all punctuation will be removed.
Then created new column called lower_dialogue where all words will be converted to lowercase. You
must get something like this:
## Rows: 1,011
## Columns: 4
## $ character <chr> "THREEPIO", "THREEPIO", "THREEPIO", "THREEPIO", "TH...
## $ dialogue <chr> "Did you hear that? They've shut down the main rea...
## $ string_dialogue <chr> "Did you hear that Theyve shut down the main react...
## $ lower_dialogue <chr> "did you hear that theyve shut down the main react...

```{r p1.2, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
dataframe$string_dialogue = gsub("[^[:alnum:][:space:]']", "", dataframe$dialogue)
dataframe$string_dialogue = gsub("'", '',dataframe$string_dialogue)
dataframe$lower_dialogue = tolower(dataframe$string_dialogue)
str(dataframe)
```
3. Create new vector named words_vector where all words from lower_dialogue column will be added
into your vector. You can use str_split() and make sure to remove empty strings like "" and english
stopwords. Print first 10 elements from your words_vector.
```{r p1.3, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(tm)
words_vector = str_split(dataframe$lower_dialogue," ",simplify = TRUE)
words_vector <- removeWords(words_vector, words = stopwords(kind = "en"))
words_vector =str_subset(words_vector, ".+")
print(words_vector[1:10])
```

4. Remove duplicates from your words_vector and store in vector named vocabulary.
If you did everything correct you will have 5955 observations in words_vector and 1706 observations in
vocabulary vector.

```{r p1.3, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
vocabulary = unique(words_vector)
print(length(words_vector))
print(length(vocabulary))

```
Part 2

5. Create new dataframe named vocab_data using vocabulary vector. Create new column named Count
and calculate how many times each word occurs in words_vector.
```{r p2.1, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
vocab_data = data.frame(vocabulary = vocabulary)
a = table(words_vector)
vocab_data$count = 1:length(vocab_data[,"vocabulary"])
for(i in 1:length(vocabulary))
{
  vocab_data[i,"count"] = a[vocab_data[i,"vocabulary"]]
}
print(head(vocab_data, n = 20))

```

6. Create new column in vocab_data named “probs” which must be equal to Count/(length of
words_vector).
```{r p2.2, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
vocab_data$probs = vocab_data$count/length(words_vector) 
head(vocab_data, n= 20)
```
7. Now read about adist() function. Describe in several sentences what does this function do.

The function returns Levenshtein string distance between two string vectors.
Levenshtein distance is the number of deletions, insertions and substitutions needed to make one string the same as the other.
It takes 8 arguments. The first and the second are the vector strings. Third one called "costs" is a numeric vector or list specifying the costs of Insertion, deletion and substitution. If costs = NULL, each operation has a unit cost.
Another important argument is called "counts". If it is TRUE, the function returns "counts" attribute containing the numbers of insertions, deletions and substitutions.
The function returns a matrix with the approximate string distances of the elements of the first and the second arguments.  matrix[1,1] shows the Levenshtein distance between the first strings of the first and the second string vectors.

Episode 2. (20 points)
8. Your goal is to create shiny application where you will have a place to type a word then by using adist()
function and vocab_data select words that have 2 edit distance from input and return words from
vocab data sorted by probability.

```{r p2.2, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
library(shiny)
library(shinythemes)
library(utils)
ui <- fluidPage(
  theme = shinytheme("journal"),
  titlePanel("Word Cloud Creator"),
  sidebarLayout(
    sidebarPanel(
     textInput("word", "Input a word: ",""),
     actionButton("submit", "Submit"),
    ),
    mainPanel(uiOutput("Text"))
  )
)
chooseWords = function(word) {
  vec = c()
  print(head(vocab_data,n = 5))
  df = vocab_data[order(vocab_data$probs),]
  print(head(vocab_data,n = 5))
  mat = adist(word,vocab_data$vocabulary)
  print(mat[1,1:5])
  for(i in 1:length(vocab_data$vocabulary)) {
    if(mat[1,i] == 2) {
      vec = c(vec,df[i,"vocabulary"])
    }
  }
  
}
server <- function(input, output) {
  
  wordsVector <- reactive({
    if(input$submit > 0)
    {
      v = chooseWords(isolate(input$word))
    }
  })
  output$Text = renderText({
    wordsVector()
    input$word
  })
  
}
shinyApp(ui, server)
```
9. Using vocab_data create interactive wordcloud.
10. The best shiny app will get extra point.
